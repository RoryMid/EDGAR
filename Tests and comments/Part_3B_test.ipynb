{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp100():\n",
    "    '''\n",
    "    Scrapes wikipedia page to get tickers for the S&P100 companies. Returns list.\n",
    "    '''\n",
    "    import requests \n",
    "    import pandas as pd\n",
    "    from bs4 import BeautifulSoup as bs\n",
    "    url  = 'https://en.wikipedia.org/wiki/S%26P_100'\n",
    "    r = requests.get(url)\n",
    "    soup = bs(r.text, 'lxml')\n",
    "    table_soup = soup.find(\"table\",{\"class\":\"wikitable sortable\"})\n",
    "    tickers = []\n",
    "\n",
    "    row_soup = table_soup.find_all('tr')\n",
    "\n",
    "    for row in row_soup[1:]:      \n",
    "        td_soup = row.find_all('td')\n",
    "        tickers.append(td_soup[0].text.replace('\\n', '').replace('BRK.B','BRK-B'))\n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = get_sp100()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yahoo_data(start_date,end_date,tickers):\n",
    "    '''\n",
    "    Uses Yahoo financials to get pricing info on each company. Creates columns for 1, 2, 3, 5, 10 daily returns. Returns dataframe.\n",
    "    '''\n",
    "    from yahoofinancials import YahooFinancials\n",
    "    import pandas as pd\n",
    "    dftot = pd.DataFrame(columns=['formatted_date','high','low','adjclose','volume','1daily_return','2daily_return','3daily_return','5daily_return','10daily_return'])\n",
    "    for i in tickers:\n",
    "        try:\n",
    "            yahoo_financials = YahooFinancials(i)\n",
    "            historical_stock_prices = yahoo_financials.get_historical_price_data(start_date, end_date, 'daily')\n",
    "            df = pd.DataFrame(historical_stock_prices[i]['prices'])\n",
    "            df1 = df[['formatted_date','high','low','adjclose','volume']].copy()\n",
    "            df1['1daily_return'] = (df1.adjclose.shift(-1) - df1.adjclose)/df1.adjclose\n",
    "            df1['2daily_return'] = (df1.adjclose.shift(-2) -df1.adjclose)/df1.adjclose\n",
    "            df1['3daily_return'] = (df1.adjclose.shift(-3) - df1.adjclose)/df1.adjclose\n",
    "            df1['5daily_return'] = (df1.adjclose.shift(-5) - df1.adjclose)/df1.adjclose\n",
    "            df1['10daily_return'] = (df1.adjclose.shift(-10) - df1.adjclose)/df1.adjclose\n",
    "            df1['ticker'] = i\n",
    "            dftot = dftot.append(df1)\n",
    "        except:\n",
    "            print(f'{i} has no data for these dates or there is an error')\n",
    "    print('Complete!')\n",
    "    return dftot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "df_returns = get_yahoo_data('2000-01-01', '2020-08-01', tickers)\n",
    "df_returns.to_csv(r'C:\\Users\\EmilyThomson\\OneDrive - Kubrick Group\\Python\\EDGAR\\stock_returns_daily_test.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
